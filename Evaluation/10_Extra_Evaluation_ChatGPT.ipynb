{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64f99099-5857-43b4-bb29-c45a2c7df2ff",
   "metadata": {},
   "source": [
    "# Model Evaluation ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a352f9-c89d-4dcd-9c6c-fd2c1bf684f4",
   "metadata": {},
   "source": [
    "# 1. Set up environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba180f47-2bab-407d-a6ba-8e63e9961403",
   "metadata": {},
   "source": [
    "Import the OpenAI, sklearn, numpy, and pandas libraries. Input your OpenAI API key. Load the CSV file containing the summary of the evaluation using Sentence Transformers into a Pandas DataFrame. This DataFrame will be overwritten with the metrics resulting from the evaluation using ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fcd2413-3870-402c-a99f-b2a6d3b88a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "api_key = 'YOUR_API_KEY'\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "path = './Evaluation_Summary/'\n",
    "file = 'evaluation_summary'\n",
    "type_file = '.csv'\n",
    "\n",
    "summary = pd.read_csv(path+file+type_file, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd8e8f3-b48b-4a1d-b770-b4550b03579b",
   "metadata": {},
   "source": [
    "# 2. Define the functions to be applied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145b1625-8116-4673-b6ad-0fcbc252d65c",
   "metadata": {},
   "source": [
    "Create the functions for performing the following operations: calculate ChatGPT cosine similarity, update the dataframe with the obtained metrics, calculate the mean cosine similarity and store it in the DataFrame that contains the summary of the ChatGPT evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38d46a7e-3154-4ae8-b429-e3604210da4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatgpt_similarity(sentence1, sentence2):\n",
    "    model = 'text-embedding-ada-002'\n",
    "    \n",
    "    embedding1 = client.embeddings.create(input = [sentence1], model=model).data[0].embedding\n",
    "    embedding2 = client.embeddings.create(input = [sentence2], model=model).data[0].embedding\n",
    "\n",
    "    embedding1_np = np.array(embedding1)\n",
    "    embedding2_np = np.array(embedding2)\n",
    "\n",
    "    similarity = cosine_similarity([embedding1_np], [embedding2_np])\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "def update_cosine_similarity_column(df):\n",
    "    for index, row in df.iterrows():\n",
    "        sentence1 = row['analysis_expected']\n",
    "        sentence2 = row['analysis_generated']\n",
    "\n",
    "        cosine_similarity = chatgpt_similarity(sentence1, sentence2)\n",
    "        \n",
    "        df.at[index, 'cosine_similarity'] = cosine_similarity\n",
    "\n",
    "    return df\n",
    "    \n",
    "def sentence_similarity_mean(df):\n",
    "    mean = df['cosine_similarity'].sum() / len(df)\n",
    "    formatted_mean = '{:.6f}'.format(mean)\n",
    "    return formatted_mean\n",
    "    \n",
    "def store_evaluation(index, ratio_type, df_template, df_results):\n",
    "    df_template.at[index, ratio_type] = sentence_similarity_mean(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f131ceae-b1cc-4223-b905-d1086f96f91b",
   "metadata": {},
   "source": [
    "# 3. Zero-Shot Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94f09d5-3395-4c31-bd3f-85db443ad3cc",
   "metadata": {},
   "source": [
    "For each ratio, load the file containing the evaluation using Sentence Transformers into a Pandas DataFrame. Call the 'update_similarity_column' function with this DataFrame as input. The function will overwrite the cosine similarity using Sentence Transformers with the cosine similarity using ChatGPT and return the DataFrame with the updated metrics. Finally, call the 'store_evaluation' function with the updated DataFrame and the summary evaluation DataFrame as input. The function will calculate the mean cosine similarity of ChatGPT and update the summary evaluation DataFrame with this value (also, specify the index and column to update as parameters to the function)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec46a5a1-5029-45e6-8bad-81d8300cfbc0",
   "metadata": {},
   "source": [
    "## Current ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cb6968d-dda3-4a0a-8dcf-d60c300302c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Zero_Shot_Evaluation/'\n",
    "file = 'zero_shot_current_ratio_similarity'\n",
    "type_file = '.csv'\n",
    "\n",
    "zs_current = pd.read_csv(path+file+type_file, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22704d22-c232-4074-a078-32087a7677a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "zs_current = update_cosine_similarity_column(zs_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62318494-1714-4ce7-a98a-64bf93255898",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_evaluation('zero_shot', 'current_ratio', summary, zs_current)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e538a50a-4e77-4ba9-a608-ea8b2921b1c1",
   "metadata": {},
   "source": [
    "## Quick ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4f086b6-9f51-4fae-8017-9a4ab3301209",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Zero_Shot_Evaluation/'\n",
    "file = 'zero_shot_quick_ratio_similarity'\n",
    "type_file = '.csv'\n",
    "\n",
    "zs_quick = pd.read_csv(path+file+type_file, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "398178d1-5bd6-464a-8554-b7e3645ac05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zs_quick = update_cosine_similarity_column(zs_quick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c2cac9-296d-4fda-957a-e89a0e79ef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_evaluation('zero_shot', 'quick_ratio', summary, zs_quick)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac85f13-af59-4f62-8e4e-400880fef6ad",
   "metadata": {},
   "source": [
    "## Cash ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cafcddae-f7c0-44da-919b-f1d417cf30a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Zero_Shot_Evaluation/'\n",
    "file = 'zero_shot_cash_ratio_similarity'\n",
    "type_file = '.csv'\n",
    "\n",
    "zs_cash = pd.read_csv(path+file+type_file, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92b3f24b-6321-469d-bb9d-d6360752deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "zs_cash = update_cosine_similarity_column(zs_cash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519ffe97-d739-4f54-a117-d43780872070",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_evaluation('zero_shot', 'cash_ratio', summary, zs_cash)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3610a23c-3665-4dd1-941c-76e02201e5a4",
   "metadata": {},
   "source": [
    "# 4. Few-Shot Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1140e621-d84c-47d1-b93a-1295815d1d9f",
   "metadata": {},
   "source": [
    "For each ratio, load the file containing the evaluation using Sentence Transformers into a Pandas DataFrame. Call the 'update_similarity_column' function with this DataFrame as input. The function will overwrite the cosine similarity using Sentence Transformers with the cosine similarity using ChatGPT and return the DataFrame with the updated metrics. Finally, call the 'store_evaluation' function with the updated DataFrame and the summary evaluation DataFrame as input. The function will calculate the mean cosine similarity of ChatGPT and update the summary evaluation DataFrame with this value (also, specify the index and column to update as parameters to the function)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e087e6b1-74a9-45b0-9100-6fd690a96112",
   "metadata": {},
   "source": [
    "## Current ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "774eceb4-7362-4ea3-9966-3879e72645a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Few_Shot_Evaluation/'\n",
    "file = 'few_shot_current_ratio_similarity'\n",
    "type_file = '.csv'\n",
    "\n",
    "fs_current = pd.read_csv(path+file+type_file, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53a0478c-80a1-479c-bb81-75f1771ee656",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_current = update_cosine_similarity_column(fs_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcf75bf9-f241-485f-bf37-409ef32c3c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_evaluation('few_shot', 'current_ratio', summary, fs_current)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b9dd54-4eed-489e-9b5b-df15f07493e7",
   "metadata": {},
   "source": [
    "## Quick ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32b294f5-8015-4851-8448-a7070f7d67da",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Few_Shot_Evaluation/'\n",
    "file = 'few_shot_quick_ratio_similarity'\n",
    "type_file = '.csv'\n",
    "\n",
    "fs_quick = pd.read_csv(path+file+type_file, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b714ffac-6283-4971-8ed5-3b6fb20e70a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_quick = update_cosine_similarity_column(fs_quick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bec367cf-3c39-46ad-832d-a2092effd7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_evaluation('few_shot', 'quick_ratio', summary, fs_quick)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88204cc-db58-4d0e-b507-945f8384ee0a",
   "metadata": {},
   "source": [
    "## Cash ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e8ab0eb-2c22-41d3-825a-522304939dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Few_Shot_Evaluation/'\n",
    "file = 'few_shot_cash_ratio_similarity'\n",
    "type_file = '.csv'\n",
    "\n",
    "fs_cash = pd.read_csv(path+file+type_file, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ab50727-3c2c-4d38-be33-a28a4ed219b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_cash = update_cosine_similarity_column(fs_cash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99ffb612-6f42-4edb-b12f-618ed43f84a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_evaluation('few_shot', 'cash_ratio', summary, fs_cash)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e933717-2f73-4a2a-8bdf-67b7f2dc82e0",
   "metadata": {},
   "source": [
    "# 5. Fine-Tuned Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72c38ff-245c-4424-8d86-98f8eca951e2",
   "metadata": {},
   "source": [
    "For each ratio, retrieve the evaluation file containing the 5 iterations (k1-k5) generated using the Cross-Validation methodology. Load the file into a Dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe078401-830e-4c14-944a-02a6238be300",
   "metadata": {},
   "source": [
    "Call the 'update_similarity_column' function with the DataFrame as input. The function will overwrite the cosine similarity using Sentence Transformers with the cosine similarity using ChatGPT and return the DataFrame with the updated metrics. Finally, call the 'store_evaluation' function with the updated DataFrame and the summary evaluation DataFrame as input. The function will calculate the mean cosine similarity of ChatGPT and update the summary evaluation DataFrame with this value (also, specify the index and column to update as parameters to the function)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df39770e-95f4-428b-acbe-797dadf314d3",
   "metadata": {},
   "source": [
    "## Current ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95962c7c-7c07-45f3-b2f5-debd62ac1c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Fine_Tuned_Evaluation/'\n",
    "file = 'fine_tuned_current_k1_k5_similarity'\n",
    "type_file = '.csv'\n",
    "ft_current_k1_k5 = pd.read_csv(path + file + type_file, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1338546-b098-4025-87d7-205076ffbd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_current_k1_k5 = update_cosine_similarity_column(ft_current_k1_k5)\n",
    "store_evaluation('fine_tuned', 'current_ratio', summary, ft_current_k1_k5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3e7883-de38-4b95-b89b-42401f7ba315",
   "metadata": {},
   "source": [
    "## Quick ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2847899a-faa3-4ee9-9016-e5906afa95cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Fine_Tuned_Evaluation/'\n",
    "file = 'fine_tuned_quick_k1_k5_similarity'\n",
    "type_file = '.csv'\n",
    "ft_quick_k1_k5 = pd.read_csv(path + file + type_file, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e5143c-075f-4af4-920b-ba98d2e703eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_quick_k1_k5 = update_cosine_similarity_column(ft_quick_k1_k5)\n",
    "store_evaluation('fine_tuned', 'quick_ratio', summary, ft_quick_k1_k5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9679d208-1b58-45be-a7b4-505fcd695453",
   "metadata": {},
   "source": [
    "## Cash ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a50cc6b-4e15-4a44-b176-fc515570cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Fine_Tuned_Evaluation/'\n",
    "file = 'fine_tuned_cash_k1_k5_similarity'\n",
    "type_file = '.csv'\n",
    "ft_cash_k1_k5 = pd.read_csv(path + file + type_file, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815ed790-e24a-4e8a-b68c-586cd74839c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_cash_k1_k5 = update_cosine_similarity_column(ft_cash_k1_k5)\n",
    "store_evaluation('fine_tuned', 'cash_ratio', summary, ft_cash_k1_k5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8e7ebc-d0cf-4ea7-8e96-3938188ce28f",
   "metadata": {},
   "source": [
    "# 6. Evaluation summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81cc818-ada2-4681-9d7e-79dfac63d94d",
   "metadata": {},
   "source": [
    "Display the DataFrame containing the evaluation summary and save it to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8cc6f2e-dbc5-4cd7-ba59-4b62d11958f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_ratio</th>\n",
       "      <th>quick_ratio</th>\n",
       "      <th>cash_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zero_shot</th>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.940716</td>\n",
       "      <td>0.937442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>few_shot</th>\n",
       "      <td>0.962357</td>\n",
       "      <td>0.965288</td>\n",
       "      <td>0.961328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fine_tuned</th>\n",
       "      <td>0.948098</td>\n",
       "      <td>0.953441</td>\n",
       "      <td>0.954979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           current_ratio quick_ratio cash_ratio\n",
       "zero_shot       0.938144    0.940716   0.937442\n",
       "few_shot        0.962357    0.965288   0.961328\n",
       "fine_tuned      0.948098    0.953441   0.954979"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f756ad87-e51e-4e0f-99f0-ad6c1fe8bfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Evaluation_Summary/'\n",
    "file = 'evaluation_summary_chatgpt'\n",
    "type_file = '.csv'\n",
    "\n",
    "summary.to_csv(path+file+type_file, index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
